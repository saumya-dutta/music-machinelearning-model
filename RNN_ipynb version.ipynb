{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d8e24-8fe8-4788-8a27-33fdad102f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize, LabelEncoder\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "class newRNN(nn.Module): # the RNN model\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential( # the layer architecture\n",
    "            nn.Linear(input_size,hidden_size*3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size*3,hidden_size*7),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size * 7, hidden_size * 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size * 10, hidden_size * 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size * 7, hidden_size * 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size*3,output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits # probability of the song belonging to each of the 8 classes\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Series.__getitem__ treating keys as positions is deprecated.\") # stop warning since not applicable\n",
    "data = pd.read_excel('Final Dataset.xlsx', header=0) #top 10 categories - atl hip hop and canadian hip hop -- so 8 categories\n",
    "category_lines = {} # initialize dict\n",
    "all_categories = [] # initialize list\n",
    "all_categories = pd.Series(data.iloc[:,1].unique()) # get a list of each different genre in the dataset\n",
    "for category in all_categories:\n",
    "    lines = data[data.iloc[:,1] == category].iloc[:,2:] # add the numerical data for each song belonging to each type of genre in the dict\n",
    "    category_lines[category] = lines\n",
    "n_categories = len(pd.Series(data.iloc[:, 1].unique())) # get number of genres/classes\n",
    "\n",
    "encoder = LabelEncoder() # for encoding classes, since currently defined as strings\n",
    "category_list = list(category_lines.keys())\n",
    "\n",
    "X = data.iloc[:,2:].to_numpy() # the X data is the feature data for each song\n",
    "y = pd.DataFrame(data.iloc[:,1]).to_numpy() # the y data is the genre for each song\n",
    "y = encoder.fit_transform(y) # applying the label encoder to the classes\n",
    "\n",
    "X_tensor = torch.tensor(X,dtype=torch.float32) # convert to tensor to pass to model\n",
    "y_tensor = torch.tensor(y,dtype=torch.long) # convert to tensor to pass to model\n",
    "\n",
    "# define parameters for model\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 11\n",
    "output_size = len(np.unique(category_list)) # number of classes\n",
    "learning_rate = 0.00001\n",
    "num_epochs = 500000\n",
    "num_splits = 5\n",
    "\n",
    "# initialize model\n",
    "model = newRNN(input_size,hidden_size,output_size)\n",
    "criterion = nn.CrossEntropyLoss() # loss function - typically good for classification problems\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "accuracies = []\n",
    "all_confusion_matrices = []\n",
    "all_true_labels = []\n",
    "all_predicted_probs = []\n",
    "all_roc_auc = []\n",
    "\n",
    "# stratified k fold cross validations since different number of songs in each class - want to maintain proportions\n",
    "skf = StratifiedKFold(n_splits=num_splits,shuffle=True,random_state=15)\n",
    "for fold, (train_indices, test_indices) in enumerate(skf.split(X_tensor,y_tensor)):\n",
    "    X_train, X_test = X_tensor[train_indices], X_tensor[test_indices] # split into train and test\n",
    "    y_train, y_test = y_tensor[train_indices], y_tensor[test_indices]\n",
    "\n",
    "    # train\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # good practice\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train) # forward step\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward() # get loss\n",
    "        optimizer.step() # take a step\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Fold [{fold + 1}/{num_splits}], Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        model.eval() # good practice\n",
    "        outputs = model(X_test)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "\n",
    "        accuracy = (predicted == y_test).sum().item() / len(y_test) # print manual accuracy for each fold\n",
    "        print(f'Fold [{fold + 1}/{num_splits}], Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "        confusion = confusion_matrix(y_test, predicted) # get confusion matrix for each fold\n",
    "        all_confusion_matrices.append(confusion) # add to total confusion\n",
    "\n",
    "        acc = accuracy_score(y_test, predicted) # use built-in sklearn accuracy for each fold\n",
    "        accuracies.append(acc) # add to total accuracy\n",
    "\n",
    "        true_labels_binary = label_binarize(y_test, classes=list(range(len(all_categories)))) # binarize labels so can find precision\n",
    "        predictions_binary = label_binarize(predicted, classes=list(range(len(all_categories))))\n",
    "\n",
    "        fpr = dict() # false positive rate\n",
    "        tpr = dict() # true positive rate\n",
    "        roc_auc = dict()\n",
    "        for i in range(len(all_categories)): # get roc curve for each fold\n",
    "            fpr[i], tpr[i], _ = roc_curve(true_labels_binary[:, 1], predictions_binary[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i]) # calculate area under the curve\n",
    "\n",
    "        plt.figure()\n",
    "        for i in range(len(all_categories)):\n",
    "            plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                                 ''.format(i, roc_auc[i]))\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "avg_confusion_matrix = sum(all_confusion_matrices) / len(all_confusion_matrices) # plot averaged confusion matrix\n",
    "\n",
    "# plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(avg_confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Average Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# print final result\n",
    "print(f\"Average accuracy: {np.mean(accuracies)*100}%\")#, average precision: {np.mean(precisions)*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
